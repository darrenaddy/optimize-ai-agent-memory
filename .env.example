# .env.example - Rename to .env and fill in your API keys

OPENAI_API_KEY="your_openai_api_key_here"

# LLM Configuration (choose one provider)
# Set to 'openai' for OpenAI models or 'ollama' for local Ollama models
LLM_PROVIDER="openai"

# Ollama Configuration (only used if LLM_PROVIDER is 'ollama')
OLLAMA_MODEL="llama2" # e.g., llama2, mistral, phi3
OLLAMA_BASE_URL="http://localhost:11434"